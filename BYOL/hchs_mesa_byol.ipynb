{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('tf2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "2180cdcf8e47e0296e6d68c9100757045f3ea5514727339509d6031e1cc4292f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# BYOL Chapman"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n",
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\kevalee shah\\anaconda3\\envs\\tf2\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Callable, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import copy\n",
    "from torchsummary import summary"
   ]
  },
  {
   "source": [
    "## Data Augmentations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoiseTransform(nn.Module):\n",
    "    def __init__(self, sigma=0.05):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        size = x.size()\n",
    "        noise = torch.normal(0, self.sigma, size)\n",
    "        return x + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleTransform(nn.Module):\n",
    "    def __init__(self, sigma=0.1):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        scalar = torch.normal(0, self.sigma, size=(1,))\n",
    "        return scalar * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Negate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return -1 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_augmentation(data_size: Tuple[int, int] = (2500, 4)) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        GaussianNoiseTransform(sigma=0.05),\n",
    "        ScaleTransform(sigma=0.1),\n",
    "        Negate(),\n",
    "    )"
   ]
  },
  {
   "source": [
    "## Encoder Wrapper"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "def mlp(dim: int, projection_size: int = 256, hidden_size: int = 4096) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(dim, hidden_size),\n",
    "        nn.BatchNorm1d(hidden_size),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(hidden_size, projection_size),\n",
    "    )\n",
    "\n",
    "\n",
    "class EncoderWrapper(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        projection_size: int = 256,\n",
    "        hidden_size: int = 4096,\n",
    "        layer: Union[str, int] = -2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.projection_size = projection_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer = layer\n",
    "\n",
    "        self._projector = None\n",
    "        self._projector_dim = None\n",
    "        self._encoded = torch.empty(0)\n",
    "        self._register_hook()\n",
    "\n",
    "    @property\n",
    "    def projector(self):\n",
    "        if self._projector is None:\n",
    "            self._projector = mlp(\n",
    "                self._projector_dim, self.projection_size, self.hidden_size\n",
    "            )\n",
    "        return self._projector\n",
    "\n",
    "    def _hook(self, _, __, output):\n",
    "        output = output.flatten(start_dim=1)\n",
    "        if self._projector_dim is None:\n",
    "            self._projector_dim = output.shape[-1]\n",
    "        self._encoded = self.projector(output)\n",
    "\n",
    "    def _register_hook(self):\n",
    "        if isinstance(self.layer, str):\n",
    "            layer = dict([*self.model.named_modules()])[self.layer]\n",
    "        else:\n",
    "            layer = list(self.model.children())[self.layer]\n",
    "\n",
    "        layer.register_forward_hook(self._hook)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        _ = self.model(x)\n",
    "        return self._encoded"
   ]
  },
  {
   "source": [
    "## BYOL and Training Code "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from itertools import chain\n",
    "from typing import Dict, List\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torch import optim\n",
    "import torch.nn.functional as func\n",
    "\n",
    "\n",
    "def normalized_mse(x: Tensor, y: Tensor) -> Tensor:\n",
    "    x = func.normalize(x, dim=-1)\n",
    "    y = func.normalize(y, dim=-1)\n",
    "    return 2 - 2 * (x * y).sum(dim=-1)\n",
    "\n",
    "\n",
    "class BYOL(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        image_size: Tuple[int, int] = (128, 128),\n",
    "        hidden_layer: Union[str, int] = -2,\n",
    "        projection_size: int = 256,\n",
    "        hidden_size: int = 4096,\n",
    "        augment_fn: Callable = None,\n",
    "        beta: float = 0.999,\n",
    "        **hparams,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.augment = default_augmentation(image_size) if augment_fn is None else augment_fn\n",
    "        self.beta = beta\n",
    "        self.encoder = EncoderWrapper(\n",
    "            model, projection_size, hidden_size, layer=hidden_layer\n",
    "        )\n",
    "        self.predictor = nn.Linear(projection_size, projection_size, hidden_size)\n",
    "        self.hparams = hparams\n",
    "        self._target = None\n",
    "\n",
    "        # self.encoder(torch.zeros(2, 3, *image_size))\n",
    "        self.encoder(torch.zeros(2, 1, *image_size))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.predictor(self.encoder(x))\n",
    "\n",
    "    @property\n",
    "    def target(self):\n",
    "        if self._target is None:\n",
    "            self._target = deepcopy(self.encoder)\n",
    "        return self._target\n",
    "\n",
    "    def update_target(self):\n",
    "        for p, pt in zip(self.encoder.parameters(), self.target.parameters()):\n",
    "            pt.data = self.beta * pt.data + (1 - self.beta) * p.data\n",
    "\n",
    "    # --- Methods required for PyTorch Lightning only! ---\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = getattr(optim, self.hparams.get(\"optimizer\", \"Adam\"))\n",
    "        lr = self.hparams.get(\"lr\", 1e-4)\n",
    "        weight_decay = self.hparams.get(\"weight_decay\", 1e-6)\n",
    "        return optimizer(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    def training_step(self, batch, *_) -> Dict[str, Union[Tensor, Dict]]:\n",
    "        x = batch[0]\n",
    "        with torch.no_grad():\n",
    "            x1, x2 = self.augment(x), self.augment(x)\n",
    "\n",
    "            \n",
    "        pred1, pred2 = self.forward(x1.float()), self.forward(x2.float())\n",
    "        with torch.no_grad():\n",
    "            targ1, targ2 = self.target(x1.float()), self.target(x2.float())\n",
    "        loss = torch.mean(normalized_mse(pred1, targ2) + normalized_mse(pred2, targ1))\n",
    "\n",
    "        self.log(\"train_loss\", loss.item())\n",
    "        self.update_target()\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_step(self, batch, *_) -> Dict[str, Union[Tensor, Dict]]:\n",
    "        x = batch[0]\n",
    "        x1, x2 = self.augment(x), self.augment(x)\n",
    "        pred1, pred2 = self.forward(x1.float()), self.forward(x2.float())\n",
    "        targ1, targ2 = self.target(x1.float()), self.target(x2.float())\n",
    "        loss = torch.mean(normalized_mse(pred1, targ2) + normalized_mse(pred2, targ1))\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_epoch_end(self, outputs: List[Dict]) -> Dict:\n",
    "        val_loss = sum(x[\"loss\"] for x in outputs) / len(outputs)\n",
    "        self.log(\"val_loss\", val_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedLightningModule(pl.LightningModule):\n",
    "    def __init__(self, model: nn.Module, **hparams):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.model(x.float())\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = getattr(optim, self.hparams.get(\"optimizer\", \"Adam\"))\n",
    "        lr = self.hparams.get(\"lr\", 1e-4)\n",
    "        weight_decay = self.hparams.get(\"weight_decay\", 1e-6)\n",
    "        return optimizer(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    def training_step(self, batch, *_) -> Dict[str, Union[Tensor, Dict]]:\n",
    "        x, y = batch\n",
    "        loss = func.cross_entropy(self.forward(x.long()), y.long())\n",
    "        self.log(\"train_loss\", loss.item())\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_step(self, batch, *_) -> Dict[str, Union[Tensor, Dict]]:\n",
    "        x, y = batch\n",
    "        y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "        loss = func.cross_entropy(self.forward(x.float()), y_tensor)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_epoch_end(self, outputs: List[Dict]) -> Dict:\n",
    "        val_loss = sum(x[\"loss\"] for x in outputs) / len(outputs)\n",
    "        self.log(\"val_loss\", val_loss.item())"
   ]
  },
  {
   "source": [
    "## Load Chapman"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "testing_flag = True\n",
    "\n",
    "if testing_flag:\n",
    "    working_directory = 'byol_chapman_testing/'\n",
    "else:\n",
    "    working_directory = 'byol_chapman/'\n",
    "if not os.path.exists(working_directory):\n",
    "    os.makedirs(working_directory)\n",
    "\n",
    "dataset_save_path = os.path.join(os.path.dirname(os.getcwd()), \"PickledData\", \"chapman\")\n",
    "path_to_patient_to_rhythm_dict = os.path.join(dataset_save_path, 'patient_to_rhythm_dict.pickle')\n",
    "\n",
    "# paths to user datasets with no nan values\n",
    "if testing_flag:\n",
    "    path_to_user_datasets = os.path.join(dataset_save_path, 'reduced_four_lead_user_datasets_no_nan.pickle')\n",
    "    path_to_test_train_split_dict = os.path.join(dataset_save_path, 'reduced_test_train_split_dict_no_nan.pickle')\n",
    "else:\n",
    "    path_to_user_datasets  = os.path.join(dataset_save_path, 'four_lead_user_datasets_no_nan.pickle')\n",
    "    path_to_test_train_split_dict = os.path.join(dataset_save_path, \"test_train_split_dict_no_nan.pickle\")\n",
    "\n",
    "with open(path_to_user_datasets, 'rb') as f:\n",
    "    user_datasets = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ -7.3540957 ,   7.23364446,   0.17799249,  32.02763874],\n",
       "       [  5.8718124 ,  -5.38643634,   6.15893108,  49.20169469],\n",
       "       [  2.19193244,  -1.89484478,   3.78605262,  38.23729682],\n",
       "       ...,\n",
       "       [-44.03105187,  40.2337431 , -16.48754457, -16.18709577],\n",
       "       [-48.83480225,  43.97261436, -16.85980413, -16.5017532 ],\n",
       "       [-53.37096958,  46.59694527, -15.31916053, -29.90105602]])"
      ]
     },
     "metadata": {},
     "execution_count": 197
    }
   ],
   "source": [
    "sample_key = list(user_datasets.keys())[0]\n",
    "user_datasets[sample_key][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_patient_to_rhythm_dict, 'rb') as f:\n",
    "    patient_to_rhythm_dict = pickle.load(f)\n",
    "\n",
    "with open(path_to_test_train_split_dict, 'rb') as f:\n",
    "    test_train_split_dict = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'SB'"
      ]
     },
     "metadata": {},
     "execution_count": 199
    }
   ],
   "source": [
    "patient_to_rhythm_dict[sample_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'AFIB': 0, 'SB': 1, 'SR': 2, 'GSVT': 3}"
      ]
     },
     "metadata": {},
     "execution_count": 171
    }
   ],
   "source": [
    "unique_rhythms_words = set(list(patient_to_rhythm_dict.values()))\n",
    "rythm_to_label_encoding = {rhythm : index for index, rhythm in enumerate(unique_rhythms_words)}\n",
    "rythm_to_label_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std_min_max_from_user_list_format(user_datasets, train_users):\n",
    "    \"\"\"\n",
    "    Obtain and means and standard deviations from a 'user-list' dataset from training users only\n",
    "    Take the mean and standard deviation for activity, white, blue, green and red light\n",
    "    \n",
    "\n",
    "    Parameters:\n",
    "\n",
    "        user_datasets\n",
    "            dataset in the 'user-list' format {user_id: [data, label]}\n",
    "        \n",
    "        train_users\n",
    "            list or set of users (corresponding to the user_ids) from which the mean and std are extracted\n",
    "\n",
    "    Return:\n",
    "        (means, stds)\n",
    "            means and stds of the particular users\n",
    "            shape: (num_channels)\n",
    "\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    for user in user_datasets.keys():\n",
    "        if user in train_users:\n",
    "            user_data = user_datasets[user][0]\n",
    "            all_data.append(user_data)\n",
    "\n",
    "    data_combined = np.concatenate(all_data)\n",
    "    \n",
    "    means = np.mean(data_combined, axis=0)\n",
    "    stds = np.std(data_combined, axis=0)\n",
    "    mins = np.min(data_combined, axis=0)\n",
    "    maxs = np.max(data_combined, axis=0)\n",
    "    \n",
    "    return (list(means), list(stds), list(mins), list(maxs))\n",
    "\n",
    "def z_normalise(data, means, stds, mins, maxs):\n",
    "    \"\"\"\n",
    "    Z-Normalise along the column for each of the leads, based on the means and stds given\n",
    "    x' = (x - mu) / std\n",
    "    \"\"\"\n",
    "    data_copy = copy.deepcopy(data)\n",
    "    for index, values in enumerate(zip(means, stds)):\n",
    "        mean = means[index]\n",
    "        std = stds[index]\n",
    "        data_copy[:,index] = (data_copy[:,index] - mean) / std\n",
    "    \n",
    "    return data_copy\n",
    "\n",
    "def normalise(data, means, stds, mins, maxs):\n",
    "    \"\"\"\n",
    "    Normalise along the column for each of the leads, using the min and max values seen in the train users. \n",
    "    x' = (x - x_min) / (x_max - x_min)\n",
    "    \"\"\"\n",
    "    data_copy = copy.deepcopy(data)\n",
    "    for index, values in enumerate(zip(mins, maxs)):\n",
    "        x_min = mins[index]\n",
    "        x_max = maxs[index]\n",
    "        data_copy[:, index] = (data_copy[:, index] - x_min) / (x_max - x_min)\n",
    "    \n",
    "    return data_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stds, mins, maxs = get_mean_std_min_max_from_user_list_format(user_datasets, test_train_split_dict['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[-1.8139955   1.96823394 -0.72447689  1.76981564]\n [-2.47797529  2.2857918  -0.18326006  2.02300656]\n [-1.93500341  1.84186734 -0.25868668  2.03596796]\n ...\n [ 0.10595234  0.92221353 -1.98838292  1.19456068]\n [ 0.11349814  0.81692537 -1.82500027  1.24680317]\n [ 0.51944241  0.49353338 -1.843918    1.17101767]]\n------------\n[[0.61215195 0.35597979 0.55128869 0.66225593]\n [0.60434451 0.35884113 0.5573366  0.66614334]\n [0.61072907 0.35484117 0.55649373 0.66634235]\n ...\n [0.63472777 0.34655468 0.53716498 0.65342365]\n [0.6348165  0.34560598 0.53899072 0.65422576]\n [0.63958982 0.34269207 0.53877932 0.65306218]]\n"
     ]
    }
   ],
   "source": [
    "z_normalised_data = z_normalise(user_datasets[sample_key][0], means, stds, mins, maxs)\n",
    "normalised_data = normalise(user_datasets[sample_key][0], means, stds, mins, maxs)\n",
    "\n",
    "print(z_normalised_data)\n",
    "print('------------')\n",
    "print(normalised_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ChapmanDataset(Dataset):\n",
    "    def __init__(self, user_datasets, patient_to_rhythm_dict, test_train_split_dict, train_or_test, normalisation_function=normalise):\n",
    "        self.samples = []\n",
    "        relevant_keys = test_train_split_dict[train_or_test]\n",
    "        means, stds, mins, maxs = get_mean_std_min_max_from_user_list_format(user_datasets, test_train_split_dict['train'])\n",
    "\n",
    "        unique_rhythms_words = set(list(patient_to_rhythm_dict.values()))\n",
    "        rythm_to_label_encoding = {rhythm : index for index, rhythm in enumerate(unique_rhythms_words)}\n",
    "        \n",
    "        for patient_id, data_label in user_datasets.items():\n",
    "            if patient_id not in relevant_keys:\n",
    "                continue\n",
    "            data = data_label[0]\n",
    "            normalised_data = normalisation_function(data, means, stds, mins, maxs)\n",
    "            tensor_data = torch.tensor(normalised_data)\n",
    "            tensor_data_size = tensor_data.size()\n",
    "            tensor_data = torch.reshape(tensor_data, (1, tensor_data_size[0], tensor_data_size[1]))\n",
    "            tensor_data = tensor_data.type(torch.DoubleTensor)\n",
    "            rhythm = patient_to_rhythm_dict[patient_id]\n",
    "            rhythm_label = rythm_to_label_encoding[rhythm]\n",
    "            tensor_rhythm_label = torch.tensor(rhythm_label)\n",
    "            tensor_rhythm_label = tensor_rhythm_label.type(torch.DoubleTensor)\n",
    "            self.samples.append((tensor_data, tensor_rhythm_label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chapman_dataset = ChapmanDataset(user_datasets, patient_to_rhythm_dict, test_train_split_dict, 'train')\n",
    "test_chapman_dataset = ChapmanDataset(user_datasets, patient_to_rhythm_dict, test_train_split_dict, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_chapman_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True\n",
    ")\n",
    "# i = 0\n",
    "# for batch, label in train_loader:\n",
    "#     print(i)\n",
    "#     i+=1 "
   ]
  },
  {
   "source": [
    "## Supervised Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]<ipython-input-222-bbabe0225a12>:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y, dtype=torch.long)\n",
      "Epoch 0:  50%|█████     | 1/2 [00:07<00:07,  7.35s/it, loss=6.93, v_num=39]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 2/2 [00:08<00:00,  4.11s/it, loss=6.93, v_num=39]\n",
      "Epoch 1:  50%|█████     | 1/2 [00:07<00:07,  7.36s/it, loss=6.87, v_num=39]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 2/2 [00:08<00:00,  4.13s/it, loss=6.87, v_num=39]\n",
      "Epoch 2:  50%|█████     | 1/2 [00:07<00:07,  7.56s/it, loss=6.82, v_num=39]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 2/2 [00:08<00:00,  4.19s/it, loss=6.82, v_num=39]\n",
      "Epoch 3:  50%|█████     | 1/2 [00:07<00:07,  7.53s/it, loss=6.77, v_num=39]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 2/2 [00:08<00:00,  4.24s/it, loss=6.77, v_num=39]\n",
      "Epoch 4:  50%|█████     | 1/2 [00:08<00:08,  8.03s/it, loss=6.74, v_num=39]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 2/2 [00:08<00:00,  4.46s/it, loss=6.74, v_num=39]\n",
      "Epoch 5:  50%|█████     | 1/2 [00:07<00:07,  7.39s/it, loss=6.7, v_num=39] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 2/2 [00:08<00:00,  4.15s/it, loss=6.7, v_num=39]\n",
      "Epoch 6:  50%|█████     | 1/2 [00:07<00:07,  7.99s/it, loss=6.67, v_num=39]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 2/2 [00:09<00:00,  4.50s/it, loss=6.67, v_num=39]\n",
      "Epoch 7:  50%|█████     | 1/2 [00:08<00:08,  8.26s/it, loss=6.64, v_num=39]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 2/2 [00:09<00:00,  4.58s/it, loss=6.64, v_num=39]\n",
      "Epoch 8:  50%|█████     | 1/2 [00:08<00:08,  8.06s/it, loss=6.62, v_num=39]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 2/2 [00:08<00:00,  4.48s/it, loss=6.62, v_num=39]\n",
      "Epoch 9:  50%|█████     | 1/2 [00:07<00:07,  7.52s/it, loss=6.6, v_num=39] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 2/2 [00:08<00:00,  4.19s/it, loss=6.6, v_num=39]\n",
      "Epoch 10:  50%|█████     | 1/2 [00:07<00:07,  7.40s/it, loss=6.58, v_num=39]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 2/2 [00:08<00:00,  4.13s/it, loss=6.58, v_num=39]\n",
      "Epoch 11:  50%|█████     | 1/2 [00:07<00:07,  7.29s/it, loss=6.56, v_num=39]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|██████████| 2/2 [00:08<00:00,  4.08s/it, loss=6.56, v_num=39]\n",
      "Epoch 12:  50%|█████     | 1/2 [00:07<00:07,  7.24s/it, loss=6.55, v_num=39]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|██████████| 2/2 [00:08<00:00,  4.04s/it, loss=6.55, v_num=39]\n",
      "Epoch 13:  50%|█████     | 1/2 [00:07<00:07,  7.74s/it, loss=6.53, v_num=39]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|██████████| 2/2 [00:08<00:00,  4.34s/it, loss=6.53, v_num=39]\n",
      "Epoch 14:   0%|          | 0/2 [00:08<?, ?it/s, loss=6.53, v_num=39]\n",
      "C:\\Users\\Kevalee Shah\\anaconda3\\envs\\tf2\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:50: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 223
    }
   ],
   "source": [
    "model = resnet18()\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "supervised = SupervisedLightningModule(model)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=25, weights_summary=None)\n",
    "train_loader = DataLoader(\n",
    "    train_chapman_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    test_chapman_dataset,\n",
    "    batch_size=128,\n",
    ")\n",
    "\n",
    "trainer.fit(supervised, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.150\n"
     ]
    }
   ],
   "source": [
    "def accuracy(pred: Tensor, labels: Tensor) -> float:\n",
    "    return (pred.argmax(dim=-1) == labels).float().mean().item()\n",
    "\n",
    "\n",
    "acc = sum([accuracy(model(x.float()), y.float()) for x, y in val_loader]) / len(val_loader)\n",
    "print(f\"Accuracy: {acc:.3f}\")"
   ]
  },
  {
   "source": [
    "## Self-Supervised Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import cpu_count\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred: Tensor, labels: Tensor) -> float:\n",
    "    return (pred.argmax(dim=-1) == labels).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch_model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-----------------------------------------------------------------------------\n           Layer (type)         Output Shape         Param #     Tr. Param #\n=============================================================================\n               Conv2d-1     [1, 64, 1250, 2]           3,136           3,136\n          BatchNorm2d-2     [1, 64, 1250, 2]             128             128\n                 ReLU-3     [1, 64, 1250, 2]               0               0\n            MaxPool2d-4      [1, 64, 625, 1]               0               0\n           BasicBlock-5      [1, 64, 625, 1]          73,984          73,984\n           BasicBlock-6      [1, 64, 625, 1]          73,984          73,984\n           BasicBlock-7     [1, 128, 313, 1]         230,144         230,144\n           BasicBlock-8     [1, 128, 313, 1]         295,424         295,424\n           BasicBlock-9     [1, 256, 157, 1]         919,040         919,040\n          BasicBlock-10     [1, 256, 157, 1]       1,180,672       1,180,672\n          BasicBlock-11      [1, 512, 79, 1]       3,673,088       3,673,088\n          BasicBlock-12      [1, 512, 79, 1]       4,720,640       4,720,640\n   AdaptiveAvgPool2d-13       [1, 512, 1, 1]               0               0\n              Linear-14            [1, 1000]         513,000         513,000\n=============================================================================\nTotal params: 11,683,240\nTrainable params: 11,683,240\nNon-trainable params: 0\n-----------------------------------------------------------------------------\n------------------------------------------------------------------------------\n           Layer (type)           Input Shape         Param #     Tr. Param #\n==============================================================================\n               Conv2d-1      [1, 1, 224, 224]           3,136           3,136\n          BatchNorm2d-2     [1, 64, 112, 112]             128             128\n                 ReLU-3     [1, 64, 112, 112]               0               0\n            MaxPool2d-4     [1, 64, 112, 112]               0               0\n           BasicBlock-5       [1, 64, 56, 56]          73,984          73,984\n           BasicBlock-6       [1, 64, 56, 56]          73,984          73,984\n           BasicBlock-7       [1, 64, 56, 56]         230,144         230,144\n           BasicBlock-8      [1, 128, 28, 28]         295,424         295,424\n           BasicBlock-9      [1, 128, 28, 28]         919,040         919,040\n          BasicBlock-10      [1, 256, 14, 14]       1,180,672       1,180,672\n          BasicBlock-11      [1, 256, 14, 14]       3,673,088       3,673,088\n          BasicBlock-12        [1, 512, 7, 7]       4,720,640       4,720,640\n   AdaptiveAvgPool2d-13        [1, 512, 7, 7]               0               0\n              Linear-14              [1, 512]         513,000         513,000\n==============================================================================\nTotal params: 11,683,240\nTrainable params: 11,683,240\nNon-trainable params: 0\n------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = resnet18(pretrained=False)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "from pytorch_model_summary import summary\n",
    "print(summary(model, torch.zeros((1, 1, 2500, 4)), show_input=False, show_hierarchical=False))\n",
    "print(summary(model, torch.zeros((1, 1, 224, 224)), show_input=True, show_hierarchical=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Epoch 0:  50%|█████     | 1/2 [00:22<00:22, 22.74s/it, loss=3.96, v_num=40]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 2/2 [00:26<00:00, 13.17s/it, loss=3.96, v_num=40]\n",
      "Epoch 1:  50%|█████     | 1/2 [00:22<00:22, 22.72s/it, loss=3.47, v_num=40]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 2/2 [00:26<00:00, 13.18s/it, loss=3.47, v_num=40]\n",
      "Epoch 2:  50%|█████     | 1/2 [00:23<00:23, 23.01s/it, loss=3.16, v_num=40]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 2/2 [00:26<00:00, 13.38s/it, loss=3.16, v_num=40]\n",
      "Epoch 3:  50%|█████     | 1/2 [00:32<00:32, 32.20s/it, loss=2.94, v_num=40]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 2/2 [00:36<00:00, 18.12s/it, loss=2.94, v_num=40]\n",
      "Epoch 4:  50%|█████     | 1/2 [00:23<00:23, 23.22s/it, loss=2.76, v_num=40]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 2/2 [00:26<00:00, 13.30s/it, loss=2.76, v_num=40]\n",
      "Epoch 5:  50%|█████     | 1/2 [00:22<00:22, 22.22s/it, loss=2.62, v_num=40]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 2/2 [00:25<00:00, 12.81s/it, loss=2.62, v_num=40]\n",
      "Epoch 6:  50%|█████     | 1/2 [00:22<00:22, 22.30s/it, loss=2.52, v_num=40]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 2/2 [00:25<00:00, 12.86s/it, loss=2.52, v_num=40]\n",
      "Epoch 7:  50%|█████     | 1/2 [00:22<00:22, 22.18s/it, loss=2.42, v_num=40]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 2/2 [00:25<00:00, 12.76s/it, loss=2.42, v_num=40]\n",
      "Epoch 8:  50%|█████     | 1/2 [00:22<00:22, 22.24s/it, loss=2.35, v_num=40]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 2/2 [00:25<00:00, 12.82s/it, loss=2.35, v_num=40]\n",
      "Epoch 9:  50%|█████     | 1/2 [00:22<00:22, 22.18s/it, loss=2.29, v_num=40]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 2/2 [00:25<00:00, 12.78s/it, loss=2.29, v_num=40]\n",
      "Epoch 9: 100%|██████████| 2/2 [00:25<00:00, 12.78s/it, loss=2.29, v_num=40]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 226
    }
   ],
   "source": [
    "model = resnet18()\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "byol = BYOL(model, image_size=(2500, 4))\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accumulate_grad_batches=2048 // 128,\n",
    "    weights_summary=None,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_chapman_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    test_chapman_dataset,\n",
    "    batch_size=128,\n",
    ")\n",
    "\n",
    "trainer.fit(byol, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]<ipython-input-222-bbabe0225a12>:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y, dtype=torch.long)\n",
      "Epoch 0:  50%|█████     | 1/2 [00:07<00:07,  7.59s/it, loss=6.88, v_num=41]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 2/2 [00:08<00:00,  4.26s/it, loss=6.88, v_num=41]\n",
      "Epoch 1:  50%|█████     | 1/2 [00:07<00:07,  7.84s/it, loss=6.83, v_num=41]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 2/2 [00:08<00:00,  4.43s/it, loss=6.83, v_num=41]\n",
      "Epoch 2:  50%|█████     | 1/2 [00:07<00:07,  7.79s/it, loss=6.78, v_num=41]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 2/2 [00:08<00:00,  4.33s/it, loss=6.78, v_num=41]\n",
      "Epoch 3:  50%|█████     | 1/2 [00:07<00:07,  7.40s/it, loss=6.74, v_num=41]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 2/2 [00:08<00:00,  4.14s/it, loss=6.74, v_num=41]\n",
      "Epoch 4:  50%|█████     | 1/2 [00:07<00:07,  7.46s/it, loss=6.71, v_num=41]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 2/2 [00:08<00:00,  4.18s/it, loss=6.71, v_num=41]\n",
      "Epoch 5:  50%|█████     | 1/2 [00:07<00:07,  7.81s/it, loss=6.68, v_num=41]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 2/2 [00:08<00:00,  4.35s/it, loss=6.68, v_num=41]\n",
      "Epoch 6:  50%|█████     | 1/2 [00:07<00:07,  7.39s/it, loss=6.65, v_num=41]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 2/2 [00:08<00:00,  4.12s/it, loss=6.65, v_num=41]\n",
      "Epoch 7:  50%|█████     | 1/2 [00:07<00:07,  7.38s/it, loss=6.63, v_num=41]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 2/2 [00:08<00:00,  4.15s/it, loss=6.63, v_num=41]\n",
      "Epoch 8:  50%|█████     | 1/2 [00:07<00:07,  7.51s/it, loss=6.6, v_num=41] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 2/2 [00:09<00:00,  4.78s/it, loss=6.6, v_num=41]\n",
      "Epoch 9:  50%|█████     | 1/2 [00:12<00:12, 12.87s/it, loss=6.59, v_num=41]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 2/2 [00:14<00:00,  7.06s/it, loss=6.59, v_num=41]\n",
      "Epoch 9: 100%|██████████| 2/2 [00:14<00:00,  7.06s/it, loss=6.59, v_num=41]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 227
    }
   ],
   "source": [
    "state_dict = model.state_dict()\n",
    "new_model = resnet18()\n",
    "new_model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "new_model.load_state_dict(state_dict)\n",
    "\n",
    "supervised = SupervisedLightningModule(new_model)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accumulate_grad_batches=2048 // 128,\n",
    "    weights_summary=None,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_chapman_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    test_chapman_dataset,\n",
    "    batch_size=128,\n",
    ")\n",
    "trainer.fit(supervised, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.250\n"
     ]
    }
   ],
   "source": [
    "def accuracy(pred: Tensor, labels: Tensor) -> float:\n",
    "    return (pred.argmax(dim=-1) == labels).float().mean().item()\n",
    "\n",
    "\n",
    "acc = sum([accuracy(new_model(x.float()), y.float()) for x, y in val_loader]) / len(val_loader)\n",
    "print(f\"Accuracy: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}